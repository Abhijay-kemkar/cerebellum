{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook walks you through the procedure to generate cropped/downsampled/correctly aligned blocks of the ground truth and predicted segmentation using the SegPrep module. You can also filter the predicted segmentation for fibers. Once the segmentation blocks are generated, you can perform an error analysis using voxel-based methods (IoU, VI) and skeleton-based methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SegPrep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srujanm/anaconda2/envs/em/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "from cerebellum.data_prep.seg_prep import *\n",
    "\n",
    "# json file with data locations and global dataset params\n",
    "# a sample is included in the package, but you need to populate it with relvant file locations and params\n",
    "with open('data_locs.json') as f:\n",
    "\tdata_locs = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing GT\n",
      "Generating block 1 from\n",
      "/home/srujanm/cerebellum/data/gt48nm_pf-align1_1k.h5\n",
      "((90, 180), (16, 556), (208, 696))\n",
      "[90, 540, 488]\n",
      "Starting relabeling of 1006 objects\n",
      "Relabeling time: 0.381241\n"
     ]
    }
   ],
   "source": [
    "print \"Preparing GT\"\n",
    "resolution = (30, 48, 48)\n",
    "gt48nm_file = data_locs[\"gt\"][\"dir\"] + data_locs[\"gt\"][\"48nm\"] # path to ground truth\n",
    "bbox = data_locs[\"gt\"][\"48nm-bbox\"] # global bbox co-ordinates\n",
    "i = 1 # TO CHANGE: block index\n",
    "print \"Generating block %d from\"%(i)\n",
    "print gt48nm_file\n",
    "zz = i*data_locs[\"block-size\"]+data_locs[\"aff-offset\"]\n",
    "gt_block_name = \"gt%04d\"%(zz)\n",
    "gt_block = SegPrep(gt_block_name, resolution)\n",
    "block_lims = ((data_locs[\"block-size\"]*i,data_locs[\"block-size\"]*(i+1)),\n",
    "              (bbox[1],bbox[4]),(bbox[2],bbox[5]))\n",
    "print block_lims\n",
    "gt_block.read(gt48nm_file, \"main\", block_lims=block_lims)\n",
    "print gt_block.shape\n",
    "gt_block.write()\n",
    "#gt_block.gen_bboxes() # NOTE: this is the longest step\n",
    "gt_block.read_bboxes() # Assuming bboxes are generated, use this to read them in\n",
    "gt_block.relabel(use_bboxes=True, print_labels=False) # get ordered labels - essential for skeletonization\n",
    "gt_block.write() # this saves your segmentation to the ./segs/<gt_block_name>/ folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting skeletonization of gt0104\n",
      "Downsampling to resolution (80, 80, 80) in 0.506502866745 seconds\n",
      "Topological thinning time for (80, 80, 80): 7.18329906464\n",
      "Endpoint vector time for (80, 80, 80): 1.64452314377\n",
      "Edge finding time for (80, 80, 80): 0.331279993057\n"
     ]
    }
   ],
   "source": [
    "# skeletonize GT for error analysis\n",
    "from cerebellum.skeletonize import gen_skeletons\n",
    "gen_skeletons(gt_block_name, resolution, overwrite_prev=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicted segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing pred\n",
      "Generating block 1 from\n",
      "/mnt/hp03/donglai/public/cere_pf/data_max_label/0104.h5\n",
      "((0, 90), (52, 3292), (1204, 4132))\n",
      "[90, 533, 488]\n",
      "(90, 540, 488)\n"
     ]
    }
   ],
   "source": [
    "print \"Preparing pred\"\n",
    "i = 1 # TO CHANGE: block index\n",
    "dsmpl = (1,6,6)\n",
    "resolution = (30,48,48)\n",
    "offset = data_locs[\"initial-seg\"][\"8nm-offset\"] # offset aligns segmentation with GT\n",
    "print \"Generating block %d from\"%(i)\n",
    "seg_file = data_locs[\"initial-seg\"][\"dir\"]+data_locs[\"initial-seg\"][\"8nm-all\"]\n",
    "zz = i*data_locs[\"block-size\"]+data_locs[\"aff-offset\"]\n",
    "if zz!=data_locs[\"aff-offset\"]: # adjust block index\n",
    "    seg_file = seg_file[:-7]+\"%04d.h5\"%(zz)\n",
    "print seg_file\n",
    "seg_block_name = \"pred-48nm-crop2gt-%04d\"%(zz)\n",
    "seg_block = SegPrep(seg_block_name, resolution)\n",
    "bbox = data_locs[\"gt\"][\"48nm-bbox\"]\n",
    "seg_block_lims = ((0,data_locs[\"block-size\"]),\n",
    "                  (max(0,dsmpl[1]*bbox[1]+offset[1]),dsmpl[1]*bbox[4]+offset[1]),\n",
    "                  (max(0,dsmpl[2]*bbox[2]+offset[2]),dsmpl[2]*bbox[5]+offset[2]))\n",
    "print seg_block_lims\n",
    "seg_block.read(seg_file, \"main\", dsmpl=dsmpl, block_lims=seg_block_lims)\n",
    "print seg_block.shape\n",
    "seg_block.padzeros(7, 1) # manually chosen to match GT block size, can easily insert a variable here\n",
    "print seg_block.shape\n",
    "seg_block.write()  # this saves your segmentation to the ./segs/<seg_block_name>/ folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fiber extraction\n",
    "\n",
    "In this stage, you zero out parts of the segmentation that are not fibers. See the `find_fiber_ids()` function in the `SegPrep` module for various filter methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 62 cell bodies\n",
      "Fiber extraction time: 0.153320 s\n",
      "Zeroing 62 objects that are not fibers\n",
      "Fiber filtering time: 1.591535\n"
     ]
    }
   ],
   "source": [
    "# seg_block.gen_bboxes() # generate bboxes of objects in segmentaiton\n",
    "# If boxes are generated, proceed with below steps\n",
    "seg_block.read_bboxes()\n",
    "\n",
    "# filter params\n",
    "filter_method = \"dsmpl\"\n",
    "filter_params = {\"dsmpl\": (4,3,3),\n",
    "                 \"bvol-thresh\": float(data_locs[\"block-size\"])/4*40}\n",
    "\n",
    "seg_block.find_fiber_ids(method=filter_method, params=filter_params) # see function for more details on setting non-default filter method and params\n",
    "seg_block.filter_fibers() # see function for more details on setting non-default filter method and params\n",
    "#seg_block.relabel(use_bboxes=True) # relabel if you wish\n",
    "seg_block.write(stage=\"filt-\"+filter_method) # this saves your filtered segmentation to the ./segs/<seg_block_name>/ folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First run error analysis on unfiltered segmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting voxel evaluation methods for pred-48nm-crop2gt-0104 against gt0104\n",
      "Found 8 GT objects completely missing\n",
      "VI split, VI merge: 0.229444, 0.219173\n"
     ]
    }
   ],
   "source": [
    "from cerebellum.error_analysis.skel_segeval import *\n",
    "\n",
    "# voxel methods - short evaluation\n",
    "# results are saved to ./err-analysis/<seg_block_name>/folder\n",
    "vox_eval = VoxEval(gt_block_name, seg_block_name, stage=None)\n",
    "vox_eval.find_misses() # find missing objects\n",
    "vox_eval.find_vi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# voxel methods - long evaluations\n",
    "# run this to generate a histogram of objects in order of deltaVI_split and deltaVI_merge\n",
    "# results are saved to ./err-analysis/<seg_block_name>/folder\n",
    "\n",
    "# vox_eval.run_fullsuite(iou_max=0.6, hist_segs=10, overwrite_prev=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set skeleton error analysis thresholds - see the SkelEval module for details\n",
    "t_om = 0.9 # omission threshold\n",
    "t_m = 0.5 # merge threshold\n",
    "t_s = 0.8 # split threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting error analysis of pred-48nm-crop2gt-0104 against skeletons of gt0104\n",
      "Warning! Labels in predicted segmentation are not consecutive. Proceeding anyway\n",
      "Starting evaluation of 29921 labels in 90x540x488 predicted segmentation against 1006 GT skeletons\n",
      "Using error thresholds: t_om=0.90, t_m=0.50, t_s=0.80\n",
      "Skeleton evaluation time: 5.21822786331\n",
      "Results:\n",
      "1 omissions, 86 merges, 307 splits, 54 hybrid, 558 correct\n",
      "GT ERL: 4899, Prediction ERL: 3040\n",
      "GT TRL: 3671311, Prediction TRL: 2633857\n",
      "Omitted RL: 0, Merged RL: 512808, Split RL: 524645\n"
     ]
    }
   ],
   "source": [
    "# skeleton methods\n",
    "# evaluate unfiltered pred against GT skeletons\n",
    "# results are saved to ./err-analysis/<seg_block_name>/folder\n",
    "skel_eval = SkelEval(gt_block_name, seg_block_name, dsmpl_res=(80,80,80), \n",
    "                     t_om=t_om, t_m=t_m, t_s=t_s, \n",
    "                     include_zero_split=False, include_zero_merge=True,\n",
    "                     stage=None, overwrite_prev=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting voxel evaluation methods for pred-48nm-crop2gt-0104 against gt0104\n",
      "Original VI split, VI merge: 0.229444, 0.219173\n",
      "After fixing 140 merges in GT flagged by skeleton analysis:\n",
      "(0.19892408344535406, 0.09704647751885559)\n",
      "Starting voxel evaluation methods for pred-48nm-crop2gt-0104 against gt0104\n",
      "Original VI split, VI merge: 0.229444, 0.219173\n",
      "After fixing 361 splits in GT flagged by skeleton analysis:\n",
      "(0.07890341036428314, 0.06783597265097327)\n"
     ]
    }
   ],
   "source": [
    "# validate skeleton methods\n",
    "# apply oracle to IDs flagged as splits and merges and check change in VI\n",
    "skel_eval.merge_oracle()\n",
    "skel_eval.split_oracle()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now carry error analysis on filtered segmentation. The error statistics should be as close as possible to the unfiltered segmentation, if your filtering method is doing a good job. You can go back up to the filtering step and readjust the filter params to improve this result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting voxel evaluation methods for pred-48nm-crop2gt-0104 against gt0104\n",
      "Found 51 GT objects completely missing\n",
      "VI split, VI merge: 0.209012, 0.270250\n",
      "Starting error analysis of pred-48nm-crop2gt-0104 against skeletons of gt0104\n",
      "Starting evaluation of 5070 labels in 90x540x488 predicted segmentation against 1006 GT skeletons\n",
      "Using error thresholds: t_om=0.80, t_m=0.20, t_s=0.70\n",
      "Skeleton evaluation time: 4.98642706871\n",
      "Results:\n",
      "19 omissions, 119 merges, 106 splits, 57 hybrid, 705 correct\n",
      "GT ERL: 4899, Prediction ERL: 3197\n",
      "GT TRL: 3671311, Prediction TRL: 2648101\n",
      "Omitted RL: 56026, Merged RL: 705352, Split RL: 261830\n"
     ]
    }
   ],
   "source": [
    "# repeat error analysis for filtered objects\n",
    "# results are saved to ./err-analysis/<seg_block_name>/<filtered>\n",
    "vox_eval = VoxEval(gt_block_name, seg_block_name, stage='filtered')\n",
    "vox_eval.find_misses() # find missing objects\n",
    "vox_eval.find_vi()\n",
    "skel_eval = SkelEval(gt_block_name, seg_block_name, dsmpl_res=(80,80,80), \n",
    "                     t_om=0.8, t_m=0.2, t_s=0.7, \n",
    "                     stage='filtered', overwrite_prev=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "em",
   "language": "python",
   "name": "em"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
